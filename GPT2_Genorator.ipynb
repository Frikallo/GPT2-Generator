{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "GPT2-Genorator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNbFKBjnGkgNbuHWF+vLlNW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Frikallo/gpt2-Generator/blob/main/GPT2_Genorator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLHTMzu_OrwL"
      },
      "source": [
        "!pip install ipywidgets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2596ORFz6XYq"
      },
      "source": [
        "!pip install torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsvwocKS6cKP"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRCd8IOkiyzu"
      },
      "source": [
        "!pip install tweepy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeqIvdQIdEpF"
      },
      "source": [
        "#@title Gpt2 Text Generation. { display-mode: \"form\" }\n",
        "Parent = 'huggingtweets/deepleffen-dril' #@param {type:\"string\"}\n",
        "Prompt = 'twitter' #@param {type:\"string\"}\n",
        "Temperature = 1 #@param {type:\"slider\", min:0.1, max:1.9, step:0.01}\n",
        "Top_K = 0 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "Top_P = 0.9 #@param {type:\"slider\", min:0, max:1.9, step:0.01}\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "button = widgets.Button(description=\"Generate\")\n",
        "tweet_generation = widgets.Button(description=\"Tweet Last Generation\")\n",
        "myLabel= widgets.Label(value='Output')\n",
        "display(button,tweet_generation,myLabel)\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "import tweepy\n",
        "tokenizer = AutoTokenizer.from_pretrained(Parent)\n",
        "model = AutoModelForCausalLM.from_pretrained(Parent)\n",
        "\n",
        "CONSUMER_KEY = 'OSkDTCyDDkih13Q8LZTJ7SK6W'\n",
        "CONSUMER_SECRET = 'iWyQAoQzLbOW2zlvBvgzC1Gv7rtWegrhOVIo1usOAnsvmOdXWG'\n",
        "ACCESS_KEY = '1292652372951363584-OcYGHfH2Bv8jbtjF0P0FFjV2055QHg'\n",
        "ACCESS_SECRET = 'xI3RUqn2V3zqGSdKXm3FeKb6vsdBakYbf1DHZxLACrEJq'\n",
        "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
        "auth.set_access_token(ACCESS_KEY, ACCESS_SECRET)\n",
        "twitter_API = tweepy.API(auth)\n",
        "\n",
        "def on_button_clicked(b):\n",
        "  print('You entered ',Prompt)\n",
        "  sequence = (Prompt)\n",
        "  inputs = tokenizer.encode(sequence, return_tensors='pt')\n",
        "  outputs = model.generate(inputs, max_length=2800, do_sample=True, temperature=(Temperature), top_k=(Top_K), top_p=(Top_P))\n",
        "  on_button_clicked.var = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "  myLabel.value = (on_button_clicked.var)\n",
        "  print(on_button_clicked.var)\n",
        "button.on_click(on_button_clicked)\n",
        "\n",
        "def tweet_innitiate(b):\n",
        "  generated = on_button_clicked.var\n",
        "  twitter_API.update_status(generated)\n",
        "  print('successfully uploaded')\n",
        "tweet_generation.on_click(tweet_innitiate)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}